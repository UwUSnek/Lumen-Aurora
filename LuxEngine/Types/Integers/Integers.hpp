#pragma once
#define LUX_H_INTEGERS





using int8  = char;		            //Signed 8-bit integer
using int16 = short;		        //Signed 16-bit integer
using int32 = int;		            //Signed 32-bit integer
using int64 = long long;		    //Signed 64-bit integer
//using int128_t int128;            //
//using int256_t int256;            //
//using int512_t int512;            //

using uint8  = unsigned char;		//Unsigned 8-bit integer. Same as char8, but specific to integer types
using uint16 = unsigned short;		//Unsigned 16-bit integer
using uint32 = unsigned int;		//Unsigned 32-bit integer
using uint64 = unsigned long ;		//Unsigned 64-bit integer
//using uint128 = uint128_t;        //
//using uint256 = uint256_t;        //
//using int512  = uint512_t;        //




using char8   = char;			    //Normal 8 bit character
using wchar8  = char8_t;			//UTF8 character (normal unsigned char)
using wchar16 = char16_t;		    //UTF16 character
using wchar32 = char32_t;		    //UTF32 character




using float32 = float;	            //Single precision floating point
using float64 = double;	            //Double precision floating point
//using float128;                   //
//using float256;                   //
//using float512;                   //

